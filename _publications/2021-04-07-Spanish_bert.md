---
title: "Spanish Pre-Trained Language Models for HealthCare Industry"
collection: publications
permalink: /publication/2021-04-07-Spanish_bert
excerpt: 'Currently transformer based model have shown high accuracy and good prediction on downstream tasks like Named Entity Recognition, Sentiment analysis etc. But the terminologies used in Healthcare sector such as names of different diseases, medicines and departments makes it difficult to predict with high accuracy. In this paper we are going to show a system for Named Entity tagging based on BETO (Spanish BERT). Experimental results have shown that our model gives better results than the current baseline of MEDDOPROF Shared task.'
date: 2021-04-07
venue: 'Proceedings of the Iberian Languages Evaluation Forum'
paperurl: 'http://ceur-ws.org/Vol-2943/meddoprof_paper7.pdf'
---
Currently transformer based model have shown high accuracy and good prediction on downstream tasks like Named Entity Recognition, Sentiment analysis etc. But the terminologies used in Healthcare sector such as names of different diseases, medicines and departments makes it difficult to predict with high accuracy. In this paper we are going to show a system for Named Entity tagging based on BETO (Spanish BERT). Experimental results have shown that our model gives better results than the current baseline of MEDDOPROF Shared task.

[Download paper here](http://ceur-ws.org/Vol-2943/meddoprof_paper7.pdf)
